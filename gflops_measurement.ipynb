{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8suser/miniconda3/envs/ldm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size: (96, 96, 96)\n",
      "Input Tensor Shape: torch.Size([1, 4, 96, 96, 96])\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "FLOPs: 333.54 GFLOPs\n",
      "Parameters: 114.74 M\n",
      "Initial VRAM Usage: 0.48 GB\n",
      "Peak VRAM Usage: 2.92 GB\n"
     ]
    }
   ],
   "source": [
    "from ldm.util import instantiate_from_config\n",
    "import yaml\n",
    "import torch\n",
    "from thop import profile  # Use thop instead of fvcore\n",
    "\n",
    "# Load YAML Config\n",
    "yaml_file = \"./configs/swinunet/swin_smt_brats.yaml\"\n",
    "with open(yaml_file, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Instantiate Model\n",
    "modelconfig = config['model']['params']['modelconfig']\n",
    "model = instantiate_from_config(modelconfig)\n",
    "\n",
    "# Ensure img_size is a tuple\n",
    "img_size = tuple(modelconfig['params']['img_size'])\n",
    "print(f\"Image Size: {img_size}\")\n",
    "\n",
    "# Ensure model is a PyTorch model\n",
    "if not isinstance(model, torch.nn.Module):\n",
    "    raise TypeError(\"instantiate_from_config did not return a valid PyTorch model!\")\n",
    "\n",
    "# Move Model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Create input tensor for FLOP analysis\n",
    "input_tensor = torch.randn((1, 4, *img_size), device=device)  \n",
    "print(f\"Input Tensor Shape: {input_tensor.shape}\")\n",
    "\n",
    "# Measure Initial VRAM Usage\n",
    "torch.cuda.empty_cache()  # Free unused memory\n",
    "torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
    "initial_memory = torch.cuda.memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Compute FLOPs using `thop`\n",
    "flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "# Measure Peak VRAM Usage\n",
    "peak_memory = torch.cuda.max_memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Print results\n",
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")  # Convert to GigaFLOPs\n",
    "print(f\"Parameters: {params / 1e6:.2f} M\")  # Convert to Million Parameters\n",
    "print(f\"Initial VRAM Usage: {initial_memory:.2f} GB\")\n",
    "print(f\"Peak VRAM Usage: {peak_memory:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size: (96, 96, 96)\n",
      "Input Tensor Shape: torch.Size([1, 4, 96, 96, 96])\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "FLOPs: 333.07 GFLOPs\n",
      "Parameters: 61.99 M\n",
      "Initial VRAM Usage: 0.01 GB\n",
      "Peak VRAM Usage: 0.01 GB\n"
     ]
    }
   ],
   "source": [
    "from ldm.util import instantiate_from_config\n",
    "import yaml\n",
    "import torch\n",
    "from thop import profile  # Use thop instead of fvcore\n",
    "\n",
    "# Load YAML Config\n",
    "yaml_file = \"./configs/swinunet/swin_unetr_brats.yaml\"\n",
    "with open(yaml_file, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Instantiate Model\n",
    "modelconfig = config['model']['params']['modelconfig']\n",
    "model = instantiate_from_config(modelconfig)\n",
    "\n",
    "# Ensure img_size is a tuple\n",
    "img_size = tuple(modelconfig['params']['img_size'])\n",
    "print(f\"Image Size: {img_size}\")\n",
    "\n",
    "# Ensure model is a PyTorch model\n",
    "if not isinstance(model, torch.nn.Module):\n",
    "    raise TypeError(\"instantiate_from_config did not return a valid PyTorch model!\")\n",
    "\n",
    "# Create input tensor for FLOP analysis\n",
    "input_tensor = torch.randn((1, 4, *img_size))  \n",
    "print(f\"Input Tensor Shape: {input_tensor.shape}\")\n",
    "\n",
    "\n",
    "# Measure Initial VRAM Usage\n",
    "torch.cuda.empty_cache()  # Free unused memory\n",
    "torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
    "initial_memory = torch.cuda.memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Compute FLOPs using `thop`\n",
    "flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "# Measure Peak VRAM Usage\n",
    "peak_memory = torch.cuda.max_memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Print results\n",
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")  # Convert to GigaFLOPs\n",
    "print(f\"Parameters: {params / 1e6:.2f} M\")  # Convert to Million Parameters\n",
    "print(f\"Initial VRAM Usage: {initial_memory:.2f} GB\")\n",
    "print(f\"Peak VRAM Usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size: (96, 96, 96)\n",
      "Input Tensor Shape: torch.Size([1, 4, 96, 96, 96])\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "FLOPs: 989.24 GFLOPs\n",
      "Parameters: 142.75 M\n",
      "Initial VRAM Usage: 0.01 GB\n",
      "Peak VRAM Usage: 0.01 GB\n"
     ]
    }
   ],
   "source": [
    "from ldm.util import instantiate_from_config\n",
    "import yaml\n",
    "import torch\n",
    "from thop import profile  # Use thop instead of fvcore\n",
    "\n",
    "# Load YAML Config\n",
    "yaml_file = \"./configs/swinunet/unetr_brats.yaml\"\n",
    "with open(yaml_file, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Instantiate Model\n",
    "modelconfig = config['model']['params']['modelconfig']\n",
    "model = instantiate_from_config(modelconfig)\n",
    "\n",
    "# Ensure img_size is a tuple\n",
    "img_size = tuple(modelconfig['params']['img_size'])\n",
    "print(f\"Image Size: {img_size}\")\n",
    "\n",
    "# Ensure model is a PyTorch model\n",
    "if not isinstance(model, torch.nn.Module):\n",
    "    raise TypeError(\"instantiate_from_config did not return a valid PyTorch model!\")\n",
    "\n",
    "# Create input tensor for FLOP analysis\n",
    "input_tensor = torch.randn((1, 4, *img_size))  \n",
    "print(f\"Input Tensor Shape: {input_tensor.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Measure Initial VRAM Usage\n",
    "torch.cuda.empty_cache()  # Free unused memory\n",
    "torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
    "initial_memory = torch.cuda.memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Compute FLOPs using `thop`\n",
    "flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "# Measure Peak VRAM Usage\n",
    "peak_memory = torch.cuda.max_memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Print results\n",
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")  # Convert to GigaFLOPs\n",
    "print(f\"Parameters: {params / 1e6:.2f} M\")  # Convert to Million Parameters\n",
    "print(f\"Initial VRAM Usage: {initial_memory:.2f} GB\")\n",
    "print(f\"Peak VRAM Usage: {peak_memory:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size: (96, 96, 96)\n",
      "Input Tensor Shape: torch.Size([1, 4, 96, 96, 96])\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm3d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose3d'>.\n",
      "FLOPs: 334.05 GFLOPs\n",
      "Parameters: 61.99 M\n",
      "Initial VRAM Usage: 0.27 GB\n",
      "Peak VRAM Usage: 1.94 GB\n"
     ]
    }
   ],
   "source": [
    "from ldm.util import instantiate_from_config\n",
    "import yaml\n",
    "import torch\n",
    "from thop import profile  # Use thop instead of fvcore\n",
    "\n",
    "# Load YAML Config\n",
    "yaml_file = \"./configs/swinunet/swlin_unetr.yaml\"\n",
    "with open(yaml_file, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Instantiate Model\n",
    "modelconfig = config['model']['params']['modelconfig']\n",
    "model = instantiate_from_config(modelconfig)\n",
    "\n",
    "# Ensure img_size is a tuple\n",
    "img_size = tuple(modelconfig['params']['img_size'])\n",
    "print(f\"Image Size: {img_size}\")\n",
    "\n",
    "# Ensure model is a PyTorch model\n",
    "if not isinstance(model, torch.nn.Module):\n",
    "    raise TypeError(\"instantiate_from_config did not return a valid PyTorch model!\")\n",
    "\n",
    "# Create input tensor for FLOP analysis\n",
    "input_tensor = torch.randn((1, 4, *img_size))  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "print(f\"Input Tensor Shape: {input_tensor.shape}\")\n",
    "\n",
    "# Measure Initial VRAM Usage\n",
    "torch.cuda.empty_cache()  # Free unused memory\n",
    "torch.cuda.reset_peak_memory_stats()  # Reset tracking\n",
    "initial_memory = torch.cuda.memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Compute FLOPs using `thop`\n",
    "flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "# Measure Peak VRAM Usage\n",
    "peak_memory = torch.cuda.max_memory_allocated() / 1e9  # Convert to GB\n",
    "\n",
    "# Print results\n",
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")  # Convert to GigaFLOPs\n",
    "print(f\"Parameters: {params / 1e6:.2f} M\")  # Convert to Million Parameters\n",
    "print(f\"Initial VRAM Usage: {initial_memory:.2f} GB\")\n",
    "print(f\"Peak VRAM Usage: {peak_memory:.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
