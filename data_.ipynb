{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as /root/datasets/Totalsegmentator/split_data.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "\n",
    "basedir = \"/root/datasets/Totalsegmentator/\"  # Replace with your actual base directory\n",
    "\n",
    "exclude_ids = {\"s0830\", \"s0045\"}  # Replace with actual IDs\n",
    "# Load CSV file\n",
    "csv_file = os.path.join(basedir, \"meta.csv\")  # Replace with actual file name\n",
    "df = pd.read_csv(csv_file, delimiter=';')\n",
    "\n",
    "df = df[~df['image_id'].isin(exclude_ids)]\n",
    "# Add full file paths to the dataframe\n",
    "df['image'] = df['image_id'].apply(lambda x: os.path.join(x, 'ct.nii.gz'))\n",
    "df['label'] = df['image_id'].map(lambda x: os.path.join(x, 'label/label_map.nii.gz'))\n",
    "df = df[[\"image\", \"split\", \"label\"]]\n",
    "# Group data by 'split' column\n",
    "split_dict = {split: df[df['split'] == split].to_dict(orient='records') for split in df['split'].unique()}\n",
    "\n",
    "# Save to JSON\n",
    "json_file = os.path.join(basedir, \"split_data.json\")\n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(split_dict, f, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "def get_segmentation_filenames(seg_dirs):\n",
    "    \"\"\"\n",
    "    Gets the sorted list of unique segmentation filenames across all subjects.\n",
    "    Ensures that all subjects have the same segmentation order.\n",
    "    \"\"\"\n",
    "    all_files = set()\n",
    "    for seg_dir in seg_dirs:\n",
    "        if os.path.exists(seg_dir):\n",
    "            all_files.update([f for f in os.listdir(seg_dir) if f.endswith(\".nii.gz\")])\n",
    "    return sorted(all_files)  # Ensures the same order for all subjects\n",
    "\n",
    "def create_label_map(seg_dir, output_path, expected_files):\n",
    "    \"\"\"\n",
    "    Creates a single label map from multiple segmentation masks.\n",
    "    \n",
    "    - Each segmentation file corresponds to a unique integer label (1, 2, ..., num_classes).\n",
    "    - The final output is a 3D NIfTI file with labeled regions.\n",
    "\n",
    "    Parameters:\n",
    "    - seg_dir (str): Path to the directory containing segmentation .nii.gz files.\n",
    "    - output_path (str): Path to save the final label map.\n",
    "    - expected_files (list): List of expected segmentation filenames in order.\n",
    "\n",
    "    Returns:\n",
    "    - output_path (str): Path to the saved label map NIfTI file.\n",
    "    \"\"\"\n",
    "    reference_nii = None\n",
    "    label_map = None  # Initialize label map\n",
    "\n",
    "    for idx, seg_file in enumerate(expected_files, start=1):  # Start labels from 1\n",
    "        file_path = os.path.join(seg_dir, seg_file)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            nii = nib.load(file_path)\n",
    "            seg_data = nii.get_fdata()\n",
    "\n",
    "            if reference_nii is None:\n",
    "                reference_nii = nii  # Store first file's metadata\n",
    "                label_map = np.zeros(seg_data.shape, dtype=np.uint8)  # Initialize label map\n",
    "\n",
    "            label_map[seg_data > 0] = idx  # Assign class index where segmentation exists\n",
    "        else:\n",
    "            print(f\"Warning: {seg_file} not found in {seg_dir}, skipping.\")\n",
    "\n",
    "    if reference_nii is None:\n",
    "        print(f\"Error: No segmentations found in {seg_dir}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Save label map as NIfTI\n",
    "    nib.save(nib.Nifti1Image(label_map, reference_nii.affine, reference_nii.header, dtype=np.uint8), output_path)\n",
    "\n",
    "    print(f\"Saved label map: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def process_subject(subject, base_dir, expected_files):\n",
    "    \"\"\"\n",
    "    Processes a single subject: converts segmentations to a label map and saves to 'label' folder.\n",
    "    \"\"\"\n",
    "    subject_path = os.path.join(base_dir, subject)\n",
    "    seg_dir = os.path.join(subject_path, \"segmentations\")  # Path to segmentation folder\n",
    "    label_dir = os.path.join(subject_path, \"label\")  # Output label folder\n",
    "    output_file = os.path.join(label_dir, \"label_map.nii.gz\")  # Output file\n",
    "\n",
    "    if os.path.exists(seg_dir):  # Check if segmentations folder exists\n",
    "        create_label_map(seg_dir, output_file, expected_files)\n",
    "    else:\n",
    "        print(f\"Segmentations folder not found for {subject}, skipping.\")\n",
    "\n",
    "def process_all_subjects(base_dir, num_workers=None):\n",
    "    \"\"\"\n",
    "    Iterates over all subject folders in base_dir using multiprocessing to speed up processing.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir (str): Path to the main directory containing all subject folders.\n",
    "    - num_workers (int, optional): Number of CPU cores to use. Default is all available cores.\n",
    "    \"\"\"\n",
    "    # Get all subject directories\n",
    "    subjects = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    seg_dirs = [os.path.join(base_dir, subject, \"segmentations\") for subject in subjects if os.path.exists(os.path.join(base_dir, subject, \"segmentations\"))]\n",
    "\n",
    "    # Get the consistent order of segmentation files across all subjects\n",
    "    expected_files = get_segmentation_filenames(seg_dirs)\n",
    "    print(expected_files, len(expected_files))\n",
    "\n",
    "    # # Use multiprocessing to process subjects in parallel\n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        pool.starmap(process_subject, [(subject, base_dir, expected_files) for subject in subjects])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adrenal_gland_left.nii.gz', 'adrenal_gland_right.nii.gz', 'aorta.nii.gz', 'atrial_appendage_left.nii.gz', 'autochthon_left.nii.gz', 'autochthon_right.nii.gz', 'brachiocephalic_trunk.nii.gz', 'brachiocephalic_vein_left.nii.gz', 'brachiocephalic_vein_right.nii.gz', 'brain.nii.gz', 'clavicula_left.nii.gz', 'clavicula_right.nii.gz', 'colon.nii.gz', 'common_carotid_artery_left.nii.gz', 'common_carotid_artery_right.nii.gz', 'costal_cartilages.nii.gz', 'duodenum.nii.gz', 'esophagus.nii.gz', 'femur_left.nii.gz', 'femur_right.nii.gz', 'gallbladder.nii.gz', 'gluteus_maximus_left.nii.gz', 'gluteus_maximus_right.nii.gz', 'gluteus_medius_left.nii.gz', 'gluteus_medius_right.nii.gz', 'gluteus_minimus_left.nii.gz', 'gluteus_minimus_right.nii.gz', 'heart.nii.gz', 'hip_left.nii.gz', 'hip_right.nii.gz', 'humerus_left.nii.gz', 'humerus_right.nii.gz', 'iliac_artery_left.nii.gz', 'iliac_artery_right.nii.gz', 'iliac_vena_left.nii.gz', 'iliac_vena_right.nii.gz', 'iliopsoas_left.nii.gz', 'iliopsoas_right.nii.gz', 'inferior_vena_cava.nii.gz', 'kidney_cyst_left.nii.gz', 'kidney_cyst_right.nii.gz', 'kidney_left.nii.gz', 'kidney_right.nii.gz', 'liver.nii.gz', 'lung_lower_lobe_left.nii.gz', 'lung_lower_lobe_right.nii.gz', 'lung_middle_lobe_right.nii.gz', 'lung_upper_lobe_left.nii.gz', 'lung_upper_lobe_right.nii.gz', 'pancreas.nii.gz', 'portal_vein_and_splenic_vein.nii.gz', 'prostate.nii.gz', 'pulmonary_vein.nii.gz', 'rib_left_1.nii.gz', 'rib_left_10.nii.gz', 'rib_left_11.nii.gz', 'rib_left_12.nii.gz', 'rib_left_2.nii.gz', 'rib_left_3.nii.gz', 'rib_left_4.nii.gz', 'rib_left_5.nii.gz', 'rib_left_6.nii.gz', 'rib_left_7.nii.gz', 'rib_left_8.nii.gz', 'rib_left_9.nii.gz', 'rib_right_1.nii.gz', 'rib_right_10.nii.gz', 'rib_right_11.nii.gz', 'rib_right_12.nii.gz', 'rib_right_2.nii.gz', 'rib_right_3.nii.gz', 'rib_right_4.nii.gz', 'rib_right_5.nii.gz', 'rib_right_6.nii.gz', 'rib_right_7.nii.gz', 'rib_right_8.nii.gz', 'rib_right_9.nii.gz', 'sacrum.nii.gz', 'scapula_left.nii.gz', 'scapula_right.nii.gz', 'skull.nii.gz', 'small_bowel.nii.gz', 'spinal_cord.nii.gz', 'spleen.nii.gz', 'sternum.nii.gz', 'stomach.nii.gz', 'subclavian_artery_left.nii.gz', 'subclavian_artery_right.nii.gz', 'superior_vena_cava.nii.gz', 'thyroid_gland.nii.gz', 'trachea.nii.gz', 'urinary_bladder.nii.gz', 'vertebrae_C1.nii.gz', 'vertebrae_C2.nii.gz', 'vertebrae_C3.nii.gz', 'vertebrae_C4.nii.gz', 'vertebrae_C5.nii.gz', 'vertebrae_C6.nii.gz', 'vertebrae_C7.nii.gz', 'vertebrae_L1.nii.gz', 'vertebrae_L2.nii.gz', 'vertebrae_L3.nii.gz', 'vertebrae_L4.nii.gz', 'vertebrae_L5.nii.gz', 'vertebrae_S1.nii.gz', 'vertebrae_T1.nii.gz', 'vertebrae_T10.nii.gz', 'vertebrae_T11.nii.gz', 'vertebrae_T12.nii.gz', 'vertebrae_T2.nii.gz', 'vertebrae_T3.nii.gz', 'vertebrae_T4.nii.gz', 'vertebrae_T5.nii.gz', 'vertebrae_T6.nii.gz', 'vertebrae_T7.nii.gz', 'vertebrae_T8.nii.gz', 'vertebrae_T9.nii.gz'] 117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basedir = \"/root/datasets/Totalsegmentator/\"  # Replace with your actual base directory\n",
    "process_all_subjects(basedir, num_workers=12)  # Use 8 CPU cores (or omit for max available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: float64\n",
      "Data: uint8\n",
      "Min Value: 0.0\n",
      "Max Value: 105.0\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Define file path\n",
    "nii_file = \"/root/datasets/Totalsegmentator/s0104/label/label_map.nii.gz\"\n",
    "\n",
    "# Load the NIfTI file\n",
    "nii = nib.load(nii_file)\n",
    "\n",
    "\n",
    "# Get the image data as a NumPy array\n",
    "data = nii.get_fdata()\n",
    "\n",
    "# Check datatype, min, and max values\n",
    "print(f\"Data Type: {data.dtype}\")\n",
    "print(f\"Data:\", nii.header.get_data_dtype())\n",
    "print(f\"Min Value: {np.min(data)}\")\n",
    "print(f\"Max Value: {np.max(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Other NIfTI Error: /root/datasets/Totalsegmentator/s0000/label/concatenated_labels.nii.gz - Compressed file ended before the end-of-stream marker was reached\n",
      "❌ Corrupted GZip File: /root/datasets/Totalsegmentator/s0011/label/concatenated_labels.nii.gz - Expected 4877349867 bytes, got 458554261 bytes from \n",
      " - could the file be damaged?\n",
      "❌ Other NIfTI Error: /root/datasets/Totalsegmentator/s0037/label/concatenated_labels.nii.gz - Compressed file ended before the end-of-stream marker was reached\n",
      "❌ Corrupted GZip File: /root/datasets/Totalsegmentator/s0045/ct.nii.gz - CRC check failed 0xe7b9154e != 0xaf073076\n",
      "❌ Other NIfTI Error: /root/datasets/Totalsegmentator/s0052/label/concatenated_labels.nii.gz - Compressed file ended before the end-of-stream marker was reached\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Run check on dataset directory\u001b[39;00m\n\u001b[1;32m     41\u001b[0m root_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/datasets/Totalsegmentator\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to your dataset path\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mcheck_nifti_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mcheck_nifti_files\u001b[0;34m(root_dir)\u001b[0m\n\u001b[1;32m     19\u001b[0m         f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# Read first 100 bytes to check integrity\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Step 2: Try loading with NiBabel\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     nii \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     nii\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# Ensure data is readable\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (gzip\u001b[38;5;241m.\u001b[39mBadGzipFile, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/envs/ldm/lib/python3.10/site-packages/nibabel/loadsave.py:111\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     is_valid, sniff \u001b[38;5;241m=\u001b[39m image_klass\u001b[38;5;241m.\u001b[39mpath_maybe_image(filename, sniff)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid:\n\u001b[0;32m--> 111\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_klass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m    114\u001b[0m matches, msg \u001b[38;5;241m=\u001b[39m _signature_matches_extension(filename)\n",
      "File \u001b[0;32m/opt/conda/envs/ldm/lib/python3.10/site-packages/nibabel/dataobj_images.py:503\u001b[0m, in \u001b[0;36mDataobjImage.from_filename\u001b[0;34m(klass, filename, mmap, keep_file_open)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap should be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mTrue, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 503\u001b[0m file_map \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilespec_to_file_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass\u001b[38;5;241m.\u001b[39mfrom_file_map(file_map, mmap\u001b[38;5;241m=\u001b[39mmmap, keep_file_open\u001b[38;5;241m=\u001b[39mkeep_file_open)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import gzip\n",
    "\n",
    "def check_nifti_files(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively iterates over all `.nii.gz` files in `root_dir`\n",
    "    and checks if they are corrupted.\n",
    "    \"\"\"\n",
    "    corrupted_files = []\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".nii.gz\"):\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                try:\n",
    "                    # Step 1: Try to open as gzip file to check for corruption\n",
    "                    with gzip.open(file_path, 'rb') as f:\n",
    "                        f.read(100)  # Read first 100 bytes to check integrity\n",
    "\n",
    "                    # Step 2: Try loading with NiBabel\n",
    "                    nii = nib.load(file_path)\n",
    "                    nii.get_fdata()  # Ensure data is readable\n",
    "                    \n",
    "                except (gzip.BadGzipFile, OSError) as e:\n",
    "                    print(f\"❌ Corrupted GZip File: {file_path} - {e}\")\n",
    "                    corrupted_files.append(file_path)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Other NIfTI Error: {file_path} - {e}\")\n",
    "                    corrupted_files.append(file_path)\n",
    "\n",
    "    if corrupted_files:\n",
    "        print(\"\\n⚠️ Found Corrupted Files:\")\n",
    "        for corrupt in corrupted_files:\n",
    "            print(f\"  - {corrupt}\")\n",
    "    else:\n",
    "        print(\"\\n✅ All NIfTI files are valid!\")\n",
    "\n",
    "# Run check on dataset directory\n",
    "root_directory = \"/root/datasets/Totalsegmentator\"  # Change this to your dataset path\n",
    "check_nifti_files(root_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File is valid: /root/datasets/Totalsegmentator/s0234/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0234/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0771/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0771/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0398/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0398/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0249/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0249/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0095/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0095/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0021/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0021/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0625/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0625/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0216/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0216/label/label_map.nii.gz\n",
      "❌ Corrupted GZip File: /root/datasets/Totalsegmentator/s0045/ct.nii.gz - CRC check failed 0xe7b9154e != 0xaf073076\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0045/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0000/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0000/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0698/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0698/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0123/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0123/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0324/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0324/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0747/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0747/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0032/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0032/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0621/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0621/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0614/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0614/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0420/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0420/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0572/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0572/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0658/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0658/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0546/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0546/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0466/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0466/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0520/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0520/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0607/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0607/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0650/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0650/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0675/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0675/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1379/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1379/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0873/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0873/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0655/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0655/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0352/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0352/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0544/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0544/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0346/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0346/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0618/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0618/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0506/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0506/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0158/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0158/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0853/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0853/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0445/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0445/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0458/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0458/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0339/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0339/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0462/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0462/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0208/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0208/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0170/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s0170/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1287/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1287/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1233/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1233/label/label_map.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1278/ct.nii.gz\n",
      "✅ File is valid: /root/datasets/Totalsegmentator/s1278/label/label_map.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import gzip\n",
    "\n",
    "# Suspected corrupted files\n",
    "suspect_files = [\n",
    "    \"/root/datasets/Totalsegmentator/s0234/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0234/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0771/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0771/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0398/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0398/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0249/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0249/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0095/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0095/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0021/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0021/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0625/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0625/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0216/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0216/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0045/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0045/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0000/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0000/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0698/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0698/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0123/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0123/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0324/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0324/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0747/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0747/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0032/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0032/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0621/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0621/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0614/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0614/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0420/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0420/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0572/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0572/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0658/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0658/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0546/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0546/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0466/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0466/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0520/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0520/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0607/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0607/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0650/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0650/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0675/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0675/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1379/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1379/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0873/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0873/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0655/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0655/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0352/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0352/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0544/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0544/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0346/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0346/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0618/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0618/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0506/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0506/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0158/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0158/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0853/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0853/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0445/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0445/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0458/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0458/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0339/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0339/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0462/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0462/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0208/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0208/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0170/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s0170/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1287/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1287/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1233/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1233/label/label_map.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1278/ct.nii.gz\",\n",
    "    \"/root/datasets/Totalsegmentator/s1278/label/label_map.nii.gz\"\n",
    "]\n",
    "\n",
    "def check_nifti_file(file_path):\n",
    "    \"\"\"Checks if a NIfTI file is corrupted.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # Step 1: Check if it's a valid gzip file\n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "            f.read(100)  # Try reading first 100 bytes\n",
    "\n",
    "        # Step 2: Try loading with NiBabel\n",
    "        nii = nib.load(file_path)\n",
    "        nii.get_fdata()  # Ensure data is readable\n",
    "\n",
    "        print(f\"✅ File is valid: {file_path}\")\n",
    "        return True\n",
    "\n",
    "    except (gzip.BadGzipFile, OSError) as e:\n",
    "        print(f\"❌ Corrupted GZip File: {file_path} - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Other NIfTI Error: {file_path} - {e}\")\n",
    "\n",
    "    return False\n",
    "\n",
    "# Run check for each suspected file\n",
    "for file in suspect_files:\n",
    "    check_nifti_file(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ldm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Keys: ['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint_path = \"./logs/2025-02-27T18-28-28_swlin_unetr_totseg/checkpoints/last.ckpt\"\n",
    "\n",
    "# Load only metadata\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)['state_dict']\n",
    "\n",
    "# Print top-level keys\n",
    "print(\"Checkpoint Keys:\", list(checkpoint.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
