model:
  base_learning_rate: 5e-6
  target: ldm.modules.ham.HAM_Seg_Trainer
  params:
    # modalities: ['t1', 't1ce', 't2', 'flair']
    # ckpt_path: ./weights/last.ckpt # to be filled
    monitor: val/dice_loss
    modelconfig:
      target: ldm.models.swinunet.swlinunetr.SwinUNETR
      params: 
        in_channels: 3
        out_channels: 1
        feature_size: 48
        img_size: [224, 224]
        # window_size: [7, 7, 7]
        # patch_size: [2, 2, 2]
        # depths: [2, 2, 2]
        # num_heads: [ 3, 6, 12, 24 ] 
        # drop_path_rate: 0.2
        use_checkpoint: False
        # use_wlin: 125
        spatial_dims: 2
    lossconfig:
      target: monai.losses.DiceLoss
      params:
        to_onehot_y: False 
        sigmoid: True
    metricconfig:
      target: monai.metrics.DiceMetric
      params:
        include_background: True
        get_not_nans: True
        reduction: mean_batch
    # first_stage_weights: ./logs/2024-09-09T21-24-50_autoencoder_vitgan_xs_cloud/checkpoints/epoch=000075.ckpt
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 8
    num_workers: 16
    wrap: false
    train:
      target: ldm.data.pam10k.PAM10KSegDataset
      params:
        is_train: True
        json_path: 'jsons/pam10kfolds.json'
        image_dir: '/home/k8suser/jo/HAM/ham10000/train/'
        fold: 4
        resize: #h,w,d
          - 224
          - 224
    validation:
      target: ldm.data.pam10k.PAM10KSegDataset
      params:
        is_train: False
        json_path: 'jsons/pam10kfolds.json'
        image_dir: '/home/k8suser/jo/HAM/ham10000/train/'
        fold: 4
        resize: #h,w,d
          - 224
          - 224

lightning:
  callbacks:
    image_logger:
      target: main.ImageLogger
      params:
        batch_frequency: 500
        max_images: 8
        increase_log_steps: False
        rescale: False
  trainer:
    benchmark: True
    # precision: 16-true
    max_epochs: 150
    devices: 0,
    check_val_every_n_epoch: 1
