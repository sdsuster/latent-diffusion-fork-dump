model:
  base_learning_rate: 1.e-4
  target: ldm.modules.vitvq3d.models.vitae.Vit_Seg_Trainer
  params:
    # modalities: ['t1', 't1ce', 't2', 'flair']
    # ckpt_path: ./weights/last.ckpt # to be filled
    monitor: val/dice_loss
    modelconfig:
      target: ldm.models.swinunet.swin_smt.SwinSMT
      params: 
        in_channels: 4
        feature_size: 48
        img_size: [96, 96, 96]
        # window_size: [7, 7, 7]
        # patch_size: [2, 2, 2]
        # depths: [2, 2, 2]
        # num_heads: [ 3, 6, 12, 24 ] 
        # drop_path_rate: 0.2
        out_channels: 3
        use_checkpoint: False
        use_moe: True
        num_layers_with_moe: 3
        num_experts: 16
        # use_wlin: 125
    lossconfig:
      target: monai.losses.DiceLoss
      params:
        to_onehot_y: False 
        sigmoid: True
    metricconfig:
      target: monai.metrics.DiceMetric
      params:
        include_background: True
        get_not_nans: True
        reduction: mean_batch
    # first_stage_weights: ./logs/2024-09-09T21-24-50_autoencoder_vitgan_xs_cloud/checkpoints/epoch=000075.ckpt
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 12
    wrap: false
    train:
      target: ldm.data.brats_monai.BratsSegFoldDataset
      params:
        data_path: ./brats_folds.json # to be filled
        fold: 5
    validation:
      target: ldm.data.brats_monai.BratsSegValFoldDataset
      params:
        data_path: ./brats_folds.json # to be filled
        fold: 5

lightning:
  callbacks:
    image_logger:
      target: main.ImageLogger
      params:
        batch_frequency: 80
        max_images: 8
        increase_log_steps: False
        rescale: False
  trainer:
    benchmark: True
    # precision: 16-true
    max_epochs: 300
    devices: 0,1,2
    check_val_every_n_epoch: 10
